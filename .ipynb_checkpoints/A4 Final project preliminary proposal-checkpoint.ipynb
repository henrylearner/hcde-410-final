{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841e2902-e3ad-4bd8-8a6e-5c2d6930eab5",
   "metadata": {},
   "source": [
    "# A4: Final Project Preliminary Proposal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bbcf96-ae66-4deb-b258-f7cfb009a26e",
   "metadata": {},
   "source": [
    "### Motivation and Problem Statement:\n",
    "\n",
    "In this analysis, I plan to examine what news outlets, topics and articles are most popular on social media platforms in relation to different news topics. In addition to seeing what types of news these social media platforms are spreading, I will examine how the sentiment scores of the titles and headlines of news articles correlate to their popularity, which can then be related back to the platforms. This analysis will help uncover some of the underlying motivations of social media platforms as well as uncover whether sentiment is related to the popularity of an article and, if they do, whether positive or negative sentiments have a greater correlation with the popularity of news. From a human-centered perspective, this will help inform people about the tendencies of the social media platforms they use and help them to understand how their psychology gravitates toward certain types of news. I hope to understand how people interact with news on social media platforms on a daily basis in order to gain a better understanding about how human psychology interacts with news on social media."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ddf514-cce5-440f-b857-de868a864672",
   "metadata": {},
   "source": [
    "### Research Questions:\n",
    "\n",
    "*Quantitative Questions*\n",
    "\n",
    "**1) Does the sentiment of an article title correlate to its popularity?**\n",
    "\n",
    "Hypothesis: I believe the more negative the sentiment of a title is, the more popular the article will be.\n",
    "\n",
    "**2) Does the sentiment of an article headline correlate to its popularity?**\n",
    "\n",
    "Hypothesis: I believe the more negative the sentiment of a title is, the more popular the article will be.\n",
    "\n",
    "**3) Is there a correlation between the sentiments of article headlines and the article titles?**\n",
    "\n",
    "Hypothesis: I believe there will be a correlation between the sentiments of the headlines and titles. <br/><br/>\n",
    "\n",
    "*Qualitative Questions*\n",
    "\n",
    "**4) Do social media platforms popularize article with certain topics over others?**\n",
    "\n",
    "Hypothesis: I believe social media platforms with more polarizing topics over others.\n",
    "\n",
    "**5) Do social media platforms popularize articles with certain sentiments over others?**\n",
    "\n",
    "Hypothesis: I believe social media platforms will popularize articles with negative sentiments over others since it will lead to more engagement.\n",
    "\n",
    "**6) Do social media platforms popularize articles with certain sources over other?**\n",
    "\n",
    "Hypothesis: I believe social media platforms will popularize articles with more notable sources over others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ad93d-533a-4bee-80d7-0095cb8c443c",
   "metadata": {},
   "source": [
    "### Data Selected for Analysis:\n",
    "\n",
    "The dataset [News Popularity in Multiple Social Media Platforms](https://archive.ics.uci.edu/ml/datasets/News+Popularity+in+Multiple+Social+Media+Platforms) represents collected data of about 100,000 different news items on four different topics: Economy, Microsoft, Obama and Palestine over the span of 8 months, between November 2015 and July 2016. To download the raw dataset via the hyperlink above, click \"Data Folder\", \"Data/\", \"News_Final.csv\". \n",
    "\n",
    "The dataset has a unique identifier for news items, the title of the news item according to the official media sources, the headline of the news item according to the official media sources, the original news outlet that published the news item, the query topic used to obtain the items in the official media sources, the date and time of the news items' publication, the final value of the news items' popularity according to the social media sources (Facebook, Google+, LinkedIn), the sentiment score of the title, and the sentiment score of the text in the news items' headline. The process to obtain these sentiment scores was carried out by applying the framework of the `qdap` [R package](https://www.rdocumentation.org/packages/qdap/versions/2.4.3) with default parametrization. Additional information about the dataset can be found [here](https://arxiv.org/pdf/1801.07055.pdf).\n",
    "\n",
    "This dataset is suitable for addressing my research goal because it provides a vast array of different news articles in relation to three different social media platforms as well as a sentiment analysis. I believe that the narrowed scope of four different news topics will allow me to understand the tendencies of these platforms rather than trying to categorize each article into topics as I move through the data. Additionally I believe Facebook, Google+ and LinkedIn are all different enough from each other to gain an understanding of the types of articles that are popluar in the different ecosystems (social, casual, professional) of social media platforms. Some things that need to be noted when looking at this dataset is that the popularity scores of the news items are given by the social media sources, and that the sentiment scores are provided by a machine learning algorithm whose details are not provided in the notebook. This could lead to biased results that either favor the social media companies and/or don't accurately reflect the sentiments of the news items.\n",
    "\n",
    "In some cases, the value of the popularity of news items at a given moment (i.e. timeslice) was not acquirable.\n",
    "These cases are denoted with the value âˆ’1, which are mostly associated to scenarios where the items are\n",
    "suggested in official media sources after two days have passed since its publication in the original news outlet.\n",
    "Such situations represent 12.4% of cases concerning the final popularity of items according to the social media\n",
    "source Facebook, and 6.2% of cases for both Google+ and LinkedIn sources.\n",
    "\n",
    "The license for this dataset is a Creative Commons Attribution 4.0 International license (CC BY 4.0), which allows for the sharing and adaptation of the datasets for any purpose, provided that the appropriate credit is given.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d76db8b-4ed6-488a-9b03-428131bde7a9",
   "metadata": {},
   "source": [
    "### Related Works:\n",
    "\n",
    "Previous research has sought to uncover some of the factors related to news popularity on social media platforms. One study titled [The Pulse of News in Social Media: Forecasting Popularity](https://www.hpl.hp.com/research/scl/papers/newsprediction/pulse.pdf) found that the most important predictor of the popularity of an article was its source. Additionally, another study titled [Are You What You Tweet? The Impact of Sentiment on Digital News Consumption and Social Media Sharing](https://pubsonline.informs.org/doi/10.1287/isre.2022.1112) found that an increase in the sentiment of content increased how much the article was shared on social media, but decreased how many people actually opened the article.\n",
    "\n",
    "Both of these studies help to inform my the way I approached this study. Specifically, the first study guided me toward asking whether certain news sources were more popular than others. And if so, I wanted to investigate if this was consistent across social media platforms. On the other hand, the second study made me wonder how much variation there was between the sentiment of the title and headline for each article. The second study mentioned previously specifically focused on Twitter to gather their data, so I wanted to see if their findings were consistent across other social media platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a317cf33-d0af-4b05-9cfc-53de5cf90ce2",
   "metadata": {},
   "source": [
    "### Methodology:\n",
    "\n",
    "In order to find the answers to my research questions, I will use different methods withinin Python depending on the variables I am using.\n",
    "\n",
    "For Questions 1, 2, and 3 I will perform **quantitative analysis** by conducting a **Spearman Rank Correlation** in Python. I chose this method because it is most suitable to find out the relationship between two ranked variables (the sentiment scores and the popularity scores) that are non-parametric. I will import the CSV dataset as a dataframe using `Pandas` and import `spearmanr` from `scipy.stats` in order to analyze the data. I will present my results by showing my model output and then describing the meaning behind the specific coefficients produced.\n",
    "\n",
    "For Questions 4, 5 and 6, I will perform **qualitative analysis** on the most popular articles for each social media platform. I chose qualitative analysis for these questions because it will allow me to order the data in descending order of popularity and then isolate the desired variable (topics, sentiments and sources). Using Python, I will look at the the 10 most popular articles for each social media platform and determine whether any patterns emerge from the data. I plan on presenting the results of my qualitative analysis as an individual table for each social media platform and each variable being looked at (3 tables for each question). Below each table I will describe if any patterns emerge. For example, Question 4 will present a table containing the variables of popularity, the topic, and the social media platform being looked at. This will be followed by a descriptive analysis. After my description will be the second table for Question 4 which will have the same exact variables except the social media platform will be different. This table will then be followed by its own descriptive analysis, and so forth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc08a7-c65c-41d3-b472-b348fdb58314",
   "metadata": {},
   "source": [
    "### Findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de375d7-a368-4191-953c-5138a6b7f52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93239, 11)\n",
      "(81637, 11)\n",
      "-0.02294281802183881\n",
      "5.5259904327745316e-11\n",
      "With a large sample size a very weak correlation Rs value can have a significant p-value. In this case, the weak correlation is not due to chance factors, but because with a large sample the low correlation is a statistically 'real' or representative of the population.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "print(df.shape)\n",
    "df = df.loc[df[\"Facebook\"] != -1]\n",
    "print(df.shape)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#calculate Spearman Rank correlation and corresponding p-value\n",
    "rho, p = spearmanr(df['SentimentTitle'], df['Facebook'])\n",
    "\n",
    "#print Spearman rank correlation and p-value\n",
    "print(rho)\n",
    "\n",
    "print(p)\n",
    "\n",
    "print(\"With a large sample size a very weak correlation Rs value can have a significant p-value. In this case, the weak correlation is not due to chance factors, but because with a large sample the low correlation is a statistically 'real' or representative of the population.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c86dfe3-ce5f-425b-9115-170b27a636a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93239, 11)\n",
      "(87495, 11)\n",
      "-0.016098803472051015\n",
      "1.9149871400409848e-06\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "print(df.shape)\n",
    "df = df.loc[df[\"GooglePlus\"] != -1]\n",
    "print(df.shape)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#calculate Spearman Rank correlation and corresponding p-value\n",
    "rho, p = spearmanr(df['SentimentTitle'], df['GooglePlus'])\n",
    "\n",
    "#print Spearman rank correlation and p-value\n",
    "print(rho)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25a90734-e2d7-4aa1-a887-523b25e95952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93239, 11)\n",
      "(87494, 11)\n",
      "-0.005139980438811487\n",
      "0.1284197911979036\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "print(df.shape)\n",
    "df = df.loc[df[\"LinkedIn\"] != -1]\n",
    "print(df.shape)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#calculate Spearman Rank correlation and corresponding p-value\n",
    "rho, p = spearmanr(df['SentimentTitle'], df['LinkedIn'])\n",
    "\n",
    "#print Spearman rank correlation and p-value\n",
    "print(rho)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0896509d-c2dc-4ef3-97b0-4ed16a110a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93239, 11)\n",
      "(81637, 11)\n",
      "0.012887608496410779\n",
      "0.0002310771416921479\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "print(df.shape)\n",
    "df = df.loc[df[\"Facebook\"] != -1]\n",
    "print(df.shape)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#calculate Spearman Rank correlation and corresponding p-value\n",
    "rho, p = spearmanr(df['SentimentHeadline'], df['Facebook'])\n",
    "\n",
    "#print Spearman rank correlation and p-value\n",
    "print(rho)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33d174ff-f098-410d-a85c-db2cf601a6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93239, 11)\n",
      "(87495, 11)\n",
      "0.008825280344565827\n",
      "0.00904120656682812\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "print(df.shape)\n",
    "df = df.loc[df[\"GooglePlus\"] != -1]\n",
    "print(df.shape)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#calculate Spearman Rank correlation and corresponding p-value\n",
    "rho, p = spearmanr(df['SentimentHeadline'], df['GooglePlus'])\n",
    "\n",
    "#print Spearman rank correlation and p-value\n",
    "print(rho)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b0581fa-b274-459f-891c-9b094bccdf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93239, 11)\n",
      "(87494, 11)\n",
      "0.014376066350593405\n",
      "2.1138687562768872e-05\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "print(df.shape)\n",
    "df = df.loc[df[\"LinkedIn\"] != -1]\n",
    "print(df.shape)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#calculate Spearman Rank correlation and corresponding p-value\n",
    "rho, p = spearmanr(df['SentimentHeadline'], df['LinkedIn'])\n",
    "\n",
    "#print Spearman rank correlation and p-value\n",
    "print(rho)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5bf08df-2255-41cd-93c0-f234698bab30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93239, 11)\n",
      "0.17748034416078898\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#calculate Spearman Rank correlation and corresponding p-value\n",
    "rho, p = spearmanr(df['SentimentTitle'], df['SentimentHeadline'])\n",
    "\n",
    "#print Spearman rank correlation and p-value\n",
    "print(rho)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "add0eef3-c4c3-4dd5-9075-9bdb4a91a7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Topic     |   Facebook |\n",
      "|:----------|-----------:|\n",
      "| economy   |      49211 |\n",
      "| obama     |      40836 |\n",
      "| obama     |      32385 |\n",
      "| obama     |      30489 |\n",
      "| economy   |      29564 |\n",
      "| obama     |      24594 |\n",
      "| obama     |      22518 |\n",
      "| microsoft |      22346 |\n",
      "| microsoft |      20371 |\n",
      "| microsoft |      19771 |\n",
      "| obama     |      19136 |\n",
      "| obama     |      17170 |\n",
      "| economy   |      16993 |\n",
      "| obama     |      16598 |\n",
      "| obama     |      15692 |\n",
      "| obama     |      15623 |\n",
      "| obama     |      15606 |\n",
      "| microsoft |      15250 |\n",
      "| obama     |      14952 |\n",
      "| microsoft |      14610 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "\n",
    "df = df.sort_values(\"Facebook\", ascending=False).head(20)\n",
    "\n",
    "df = df[[\"Topic\", \"Facebook\"]]\n",
    "\n",
    "print(df.to_markdown(index=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f0be4bda-084b-4f70-93ef-6f4dde1eb50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Topic     |   GooglePlus |\n",
      "|:----------|-------------:|\n",
      "| economy   |         1267 |\n",
      "| microsoft |         1016 |\n",
      "| microsoft |         1001 |\n",
      "| microsoft |          973 |\n",
      "| economy   |          804 |\n",
      "| microsoft |          781 |\n",
      "| economy   |          774 |\n",
      "| obama     |          725 |\n",
      "| obama     |          666 |\n",
      "| microsoft |          577 |\n",
      "| microsoft |          555 |\n",
      "| microsoft |          544 |\n",
      "| microsoft |          504 |\n",
      "| economy   |          468 |\n",
      "| obama     |          463 |\n",
      "| obama     |          451 |\n",
      "| microsoft |          436 |\n",
      "| microsoft |          435 |\n",
      "| obama     |          432 |\n",
      "| obama     |          425 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "\n",
    "df = df.sort_values(\"GooglePlus\", ascending=False).head(20)\n",
    "\n",
    "df = df[[\"Topic\", \"GooglePlus\"]]\n",
    "\n",
    "print(df.to_markdown(index=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a3eb1525-124f-4b7c-bf37-e1e6acc0f88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Topic     |   LinkedIn |\n",
      "|:----------|-----------:|\n",
      "| microsoft |      20341 |\n",
      "| microsoft |      19737 |\n",
      "| microsoft |      18004 |\n",
      "| microsoft |      10465 |\n",
      "| microsoft |       9237 |\n",
      "| microsoft |       8115 |\n",
      "| microsoft |       6848 |\n",
      "| microsoft |       6682 |\n",
      "| obama     |       6362 |\n",
      "| microsoft |       5222 |\n",
      "| economy   |       4328 |\n",
      "| microsoft |       4259 |\n",
      "| microsoft |       4059 |\n",
      "| economy   |       3716 |\n",
      "| microsoft |       3652 |\n",
      "| economy   |       3433 |\n",
      "| microsoft |       3128 |\n",
      "| microsoft |       3087 |\n",
      "| microsoft |       2963 |\n",
      "| microsoft |       2653 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "\n",
    "df = df.sort_values(\"LinkedIn\", ascending=False).head(20)\n",
    "\n",
    "df = df[[\"Topic\", \"LinkedIn\"]]\n",
    "\n",
    "print(df.to_markdown(index=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f78d682d-b475-4d8f-90fd-84983c4ad6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   SentimentTitle |   SentimentHeadline |   Facebook |\n",
      "|-----------------:|--------------------:|-----------:|\n",
      "|        0.0708683 |           0.18474   |      49211 |\n",
      "|        0.118585  |          -0.1445    |      40836 |\n",
      "|       -0.125     |           0.168878  |      32385 |\n",
      "|        0         |          -0.0573539 |      30489 |\n",
      "|       -0.113067  |          -0.104257  |      29564 |\n",
      "|        0         |          -0.0573539 |      24594 |\n",
      "|        0.265165  |           0.100051  |      22518 |\n",
      "|       -0.144338  |          -0.0191366 |      22346 |\n",
      "|       -0.0376889 |           0.200403  |      20371 |\n",
      "|        0.149691  |          -0.206576  |      19771 |\n",
      "|       -0.0416667 |          -0.104257  |      19136 |\n",
      "|       -0.0131762 |          -0.0567511 |      17170 |\n",
      "|       -0.0416667 |           0.0693172 |      16993 |\n",
      "|       -0.0610515 |          -0.243403  |      16598 |\n",
      "|       -0.102062  |          -0.436657  |      15692 |\n",
      "|        0         |           0.0818317 |      15623 |\n",
      "|        0         |           0         |      15606 |\n",
      "|       -0.0143669 |          -0.0920212 |      15250 |\n",
      "|        0.0790569 |           0.0545545 |      14952 |\n",
      "|        0.0416667 |          -0.0889391 |      14610 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "\n",
    "df = df.sort_values(\"Facebook\", ascending=False).head(20)\n",
    "\n",
    "df = df[[\"SentimentTitle\", \"SentimentHeadline\", \"Facebook\"]]\n",
    "\n",
    "print(df.to_markdown(index=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5e6fc92a-98c2-44e9-897c-f1c849b3cff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   SentimentTitle |   SentimentHeadline |   GooglePlus |\n",
      "|-----------------:|--------------------:|-------------:|\n",
      "|       -0.0416667 |          0.0693172  |         1267 |\n",
      "|       -0.166667  |         -0.0781828  |         1016 |\n",
      "|        0         |         -0.375326   |         1001 |\n",
      "|       -0.144338  |         -0.0191366  |          973 |\n",
      "|       -0.286581  |         -0.0196419  |          804 |\n",
      "|       -0.166667  |         -0.00326093 |          781 |\n",
      "|       -0.113067  |         -0.104257   |          774 |\n",
      "|       -0.0368932 |         -0.0340529  |          725 |\n",
      "|        0.09375   |          0.0340965  |          666 |\n",
      "|       -0.0895255 |         -0.0602381  |          577 |\n",
      "|        0.0706653 |          0.07       |          555 |\n",
      "|        0.0954798 |          0.11875    |          544 |\n",
      "|       -0.0883883 |         -0.0369244  |          504 |\n",
      "|        0.104494  |          0.0781929  |          468 |\n",
      "|        0         |          0          |          463 |\n",
      "|        0.0441942 |          0.338004   |          451 |\n",
      "|        0.0441942 |         -0.14602    |          436 |\n",
      "|        0.0441942 |         -0.101448   |          435 |\n",
      "|       -0.0833333 |          0.0646363  |          432 |\n",
      "|        0.265165  |          0.100051   |          425 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "\n",
    "df = df.sort_values(\"GooglePlus\", ascending=False).head(20)\n",
    "\n",
    "df = df[[\"SentimentTitle\", \"SentimentHeadline\", \"GooglePlus\"]]\n",
    "\n",
    "print(df.to_markdown(index=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "65e83d06-a8de-4eab-a1dc-5719eccef5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   SentimentTitle |   SentimentHeadline |   LinkedIn |\n",
      "|-----------------:|--------------------:|-----------:|\n",
      "|        0.0706653 |          0.07       |      20341 |\n",
      "|        0.0954798 |          0.11875    |      19737 |\n",
      "|        0.0592927 |         -0.1125     |      18004 |\n",
      "|        0         |          0.245495   |      10465 |\n",
      "|       -0.0109801 |          0.136386   |       9237 |\n",
      "|        0.102062  |          0.0818317  |       8115 |\n",
      "|        0.051031  |          0          |       6848 |\n",
      "|        0.0944911 |         -0.028677   |       6682 |\n",
      "|        0.0578854 |         -0.133436   |       6362 |\n",
      "|       -0.0333333 |         -0.0279508  |       5222 |\n",
      "|        0.125     |          0.10549    |       4328 |\n",
      "|        0.051031  |          0.129099   |       4259 |\n",
      "|        0.285052  |          0.346586   |       4059 |\n",
      "|       -0.391312  |         -0.384448   |       3716 |\n",
      "|        0.0833333 |          0.108821   |       3652 |\n",
      "|        0.100504  |          0.0313594  |       3433 |\n",
      "|       -0.108855  |          0.0183859  |       3128 |\n",
      "|        0.260417  |         -0.00283506 |       3087 |\n",
      "|       -0.166667  |         -0.0781828  |       2963 |\n",
      "|       -0.150756  |         -0.10074    |       2653 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "\n",
    "df = df.sort_values(\"LinkedIn\", ascending=False).head(20)\n",
    "\n",
    "df = df[[\"SentimentTitle\", \"SentimentHeadline\", \"LinkedIn\"]]\n",
    "\n",
    "print(df.to_markdown(index=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0a1c4c2b-4ccf-450a-90cb-4684f2fb5e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Source             |   Facebook |\n",
      "|:-------------------|-----------:|\n",
      "| New Zealand Herald |      49211 |\n",
      "| Breitbart News     |      40836 |\n",
      "| New York Times     |      32385 |\n",
      "| CNN                |      30489 |\n",
      "| New York Times     |      29564 |\n",
      "| CNN                |      24594 |\n",
      "| Breitbart News     |      22518 |\n",
      "| Telegraph.co.uk    |      22346 |\n",
      "| GameZone           |      20371 |\n",
      "| GameZone           |      19771 |\n",
      "| Liberty News Now   |      19136 |\n",
      "| Global Grind       |      17170 |\n",
      "| CNNMoney           |      16993 |\n",
      "| Fox News           |      16598 |\n",
      "| FrontPage Magazine |      15692 |\n",
      "| New York Times     |      15623 |\n",
      "| Washington Post    |      15606 |\n",
      "| The Verge          |      15250 |\n",
      "| WPEC               |      14952 |\n",
      "| Investopedia       |      14610 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "\n",
    "df = df.sort_values(\"Facebook\", ascending=False).head(20)\n",
    "\n",
    "df = df[[\"Source\", \"Facebook\"]]\n",
    "\n",
    "print(df.to_markdown(index=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f370d173-877a-4caf-b140-4a958ec2c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Source                               |   GooglePlus |\n",
      "|:-------------------------------------|-------------:|\n",
      "| CNNMoney                             |         1267 |\n",
      "| The Verge                            |         1016 |\n",
      "| The Verge                            |         1001 |\n",
      "| Telegraph.co.uk                      |          973 |\n",
      "| Narendra Modi (press release) (blog) |          804 |\n",
      "| ZDNet                                |          781 |\n",
      "| New York Times                       |          774 |\n",
      "| Raw Story                            |          725 |\n",
      "| Breitbart News                       |          666 |\n",
      "| The Verge                            |          577 |\n",
      "| TechCrunch                           |          555 |\n",
      "| Techcrunch                           |          544 |\n",
      "| The Intercept                        |          504 |\n",
      "| The Guardian                         |          468 |\n",
      "| Washington Post                      |          463 |\n",
      "| The Hill (blog)                      |          451 |\n",
      "| Forbes                               |          436 |\n",
      "| TechCrunch                           |          435 |\n",
      "| The New Yorker (satire)              |          432 |\n",
      "| Breitbart News                       |          425 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "\n",
    "df = df.sort_values(\"GooglePlus\", ascending=False).head(20)\n",
    "\n",
    "df = df[[\"Source\", \"GooglePlus\"]]\n",
    "\n",
    "print(df.to_markdown(index=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "06473a04-7a20-420c-b486-f9b1150ed1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Source                  |   LinkedIn |\n",
      "|:------------------------|-----------:|\n",
      "| TechCrunch              |      20341 |\n",
      "| Techcrunch              |      19737 |\n",
      "| LinkedIn (blog)         |      18004 |\n",
      "| TIME                    |      10465 |\n",
      "| CNBC                    |       9237 |\n",
      "| The Verge               |       8115 |\n",
      "| Wall Street Journal     |       6848 |\n",
      "| The Wall Street Journal |       6682 |\n",
      "| Politico                |       6362 |\n",
      "| Bloomberg               |       5222 |\n",
      "| Winnipeg Free Press     |       4328 |\n",
      "| CNN Money               |       4259 |\n",
      "| Forbes                  |       4059 |\n",
      "| Winnipeg Free Press     |       3716 |\n",
      "| New York Times          |       3652 |\n",
      "| Winnipeg Free Press     |       3433 |\n",
      "| Inc.com                 |       3128 |\n",
      "| Inc.com                 |       3087 |\n",
      "| The Verge               |       2963 |\n",
      "| WIRED                   |       2653 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"News_Final.csv\")\n",
    "\n",
    "df = df.sort_values(\"LinkedIn\", ascending=False).head(20)\n",
    "\n",
    "df = df[[\"Source\", \"LinkedIn\"]]\n",
    "\n",
    "print(df.to_markdown(index=False)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ee9cb-4942-4385-a434-9e2347857a45",
   "metadata": {},
   "source": [
    "### Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914e21f-077b-4464-8154-5e78f3883fa9",
   "metadata": {},
   "source": [
    "### Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c673c44-677e-4c20-a62e-643be6efea7e",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "Torgo, Lus & Moniz, Nuno. (2018). News Popularity in Multiple Social Media Platforms. UCI Machine Learning Repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
